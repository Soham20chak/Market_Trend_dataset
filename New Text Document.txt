cd home
cd ubh01
cd hadoop-2.7.1
cd sbin
./start-dfs.sh
jps
hadoop fs -mkdir /home/ubh01/hadoop-2.7.1/sbin/marketdata
hadoop fs -put /home/ubh01/Downloads/shopping_trends.csv /home/ubh01/hadoop-2.7.1/sbin/marketdata







hive
use default;
create table market_trend(id int,age int,gender string,items string,category string,amount int,location string,size string,color string,season string,rating float,subs string) row format delimited fields terminated by ',' stored as textfile location '/home/ubh01/hadoop-2.7.1/sbin/marketdata/';


partitioning :
static -
create table static_partition_table(id int,age int,gender string,items string,category string,amount int,size string,color string,season string,rating float,subs string) partitioned by (location string);

insert into table static_partition_table partition(location='Oregon') select id,age,gender,items,category,amount,size,color,season,rating,subs from market_trend where location='Oregon';

select * from static_partition_table;


dynamic -
hive> set hive.exec.dynamic.partition.mode=nonstrict;
hive> create table dynamic_partition_table(id int,age int,gender string,items string,category string,amount int,size string,color string,season string,rating float,subs string) partitioned by (location string);

insert into table dynamic_partition_table partition(location) select id,age,gender,items,category,amount,size,color,season,rating,subs from market_trend where location='Oregon';


bucketing - 
create table bucketing_table(id int,age int,gender string,items string,category string,amount int,location string,size string,color string,season string,rating float,subs string) clustered by (amount) into 5 buckets stored as textfile;

insert into bucketing_table select * from market_trend;



